{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d81fc5-6973-4604-8d79-0bcff95cce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8ef0c0-62ff-4d25-8e8b-7572cc6e7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_landmarks_dataset = pd.read_csv('E:\\Sharvil\\Code\\PBL SEM IV\\Computer Vision\\\\final_hand_landmarks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc872104-fd0a-4229-b5db-24d0d6982d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_train = hand_landmarks_dataset.iloc[:,:-1]\n",
    "labels_train = hand_landmarks_dataset[['class']]\n",
    "class_names = ['noGesture','ThumbsDown','ThumbsUp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18f9e76-451b-4b71-852a-a0ad87a78fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(63,)),\n",
    "    keras.layers.Dense(45,activation='relu'),\n",
    "    keras.layers.Dense(45,activation='relu'),\n",
    "    keras.layers.Dense(45,activation='relu'),\n",
    "    keras.layers.Dense(3,activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb105a78-4bc3-4b28-9de1-95f7316ec18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2cf84d9-a833-4b2f-97a8-7ac443d5271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 0.4399 - accuracy: 0.7979\n",
      "Epoch 2/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1146 - accuracy: 0.9650\n",
      "Epoch 3/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9759\n",
      "Epoch 4/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0533 - accuracy: 0.9839\n",
      "Epoch 5/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0451 - accuracy: 0.9861\n",
      "Epoch 6/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0323 - accuracy: 0.9908\n",
      "Epoch 7/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9907\n",
      "Epoch 8/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9908\n",
      "Epoch 9/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9924\n",
      "Epoch 10/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9948\n",
      "Epoch 11/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9927\n",
      "Epoch 12/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9918\n",
      "Epoch 13/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9912\n",
      "Epoch 14/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0178 - accuracy: 0.9950\n",
      "Epoch 15/15\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0177 - accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eeb60ed410>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(landmarks_train,labels_train,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da24eba5-de4d-4128-a202-82b7f0d1f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ef37a1-6948-4c0a-b96f-cd82fbd5553d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[43mmodel\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSharvil\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPBL SEM IV\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mComputer Vision\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mml_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, 'E:\\Sharvil\\Code\\PBL SEM IV\\Computer Vision\\ml_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5d3eed-66d8-45b3-8234-8c283651ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load('E:\\Sharvil\\Code\\PBL SEM IV\\Computer Vision\\ml_model.pkl')\n",
    "class_names = ['noGesture','ThumbsDown','ThumbsUp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90907f8-1565-4f16-b22f-bacebbe47760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import win32gui\n",
    "import win32process\n",
    "import win32api\n",
    "import win32con\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0639f9-962d-4789-ac12-c95bdcdf41c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_gesture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 160\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m predicted_class_index \u001b[38;5;129;01min\u001b[39;00m gesture_actions:\n\u001b[0;32m    158\u001b[0m                 gesture_actions[predicted_class_index]()\n\u001b[1;32m--> 160\u001b[0m         frame \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[43mpredicted_gesture\u001b[49m, org, font, fontScale, color, thickness, lineType)\n\u001b[0;32m    164\u001b[0m cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaptures\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_gesture' is not defined"
     ]
    }
   ],
   "source": [
    "def get_active_browser_title():\n",
    "    window = win32gui.GetForegroundWindow()\n",
    "    pid = win32process.GetWindowThreadProcessId(window)[1]\n",
    "    handle = win32api.OpenProcess(win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ, False, pid)\n",
    "    exe_path = win32process.GetModuleFileNameEx(handle, 0)\n",
    "    return os.path.basename(exe_path)\n",
    "\n",
    "def is_doc_viewer_application(application):\n",
    "    doc_viewer_application_list = ['explorer.exe', 'vlc.exe', 'AcroRd32.exe', 'FoxitReader.exe', 'NotroPDFReader.exe', 'SumatraPDF.exe', 'PDFXEdit.exe', 'WINWORD.EXE', 'EXCEL.EXE', 'POWERPNT.EXE', 'Acrobat.exe', 'notepad.exe', 'write.exe']\n",
    "    return any(app.lower() in application.lower() for app in doc_viewer_application_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MediaPipe initialization\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Video capture initialization\n",
    "cam = cv.VideoCapture(0)\n",
    "\n",
    "thumbs_up = False\n",
    "thumbs_up_2 = False\n",
    "thumbs_up_3 = 0\n",
    "\n",
    "thumbs_down = False\n",
    "thumbs_down_2 = False\n",
    "thumbs_down_3=0\n",
    "tic_up = 0\n",
    "tic_down = 0\n",
    "\n",
    "org = (50, 50)  # Origin point for text\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color = (255, 255, 255)  # White color\n",
    "thickness = 2\n",
    "lineType = cv.LINE_AA\n",
    "\n",
    "def thumbsUp():\n",
    "    global thumbs_up, thumbs_up_2, thumbs_up_3, tic_up\n",
    "    if thumbs_up:\n",
    "        if time.perf_counter() - tic_up > 1:\n",
    "            thumbs_up_2 = True\n",
    "            thumbs_up_3+=1\n",
    "        \n",
    "    else:\n",
    "        thumbs_up = True\n",
    "        tic_up = time.perf_counter()\n",
    "\n",
    "    if thumbs_up_2:\n",
    "        if thumbs_up_3 == 1:\n",
    "            if active_browser_title.lower() == \"vlc.exe\":\n",
    "                pyautogui.press(\"space\")\n",
    "\n",
    "            else:\n",
    "                pyautogui.press(\"right\")\n",
    "                                \n",
    "            thumbs_up = False\n",
    "            thumbs_up_2 = False\n",
    "            thumbs_up_3 = 0\n",
    "            tic_up = 0\n",
    "        \n",
    "                    \n",
    "    # Reset thumbs-down variables when thumbs-up is detected\n",
    "    thumbs_down = False\n",
    "    thumbs_down_2 = False\n",
    "    thumbs_down_3=0\n",
    "\n",
    "\n",
    "def thumbsDown():\n",
    "    global thumbs_down, thumbs_down_2, thumbs_down_3, tic_down\n",
    "    if thumbs_down:\n",
    "        if time.perf_counter() - tic_down > 1:\n",
    "            thumbs_down_2 = True\n",
    "            thumbs_down_3+=1\n",
    "        \n",
    "    else:\n",
    "        thumbs_down = True\n",
    "        tic_down = time.perf_counter()\n",
    "\n",
    "    if thumbs_down_2:\n",
    "        if thumbs_down_3 == 1:    \n",
    "            pyautogui.press(\"left\")\n",
    "            \n",
    "            thumbs_down = False\n",
    "            thumbs_down_2 = False\n",
    "            thumbs_down_3=0\n",
    "            tic_down = 0\n",
    "            \n",
    "                    \n",
    "    # Reset thumbs-up variables when thumbs-down is detected\n",
    "    thumbs_up = False\n",
    "    thumbs_up_2 = False\n",
    "    thumbs_up_3=0\n",
    "\n",
    "\n",
    "def ignore():\n",
    "    global thumbs_up, thumbs_up_2, thumbs_up_3, thumbs_down, thumbs_down_2, thumbs_down_3\n",
    "    \n",
    "    thumbs_up=False\n",
    "    thumbs_up_2 = False\n",
    "    thumbs_up_3=0 \n",
    "    thumbs_down = False\n",
    "    thumbs_down_2 = False\n",
    "    thumbs_down_3=0    \n",
    "\n",
    "# Main loop for capturing hand landmarks and making predictions\n",
    "while True:\n",
    "    success, frame = cam.read()\n",
    "    if not success:\n",
    "        print(\"No frame to show\")\n",
    "        continue\n",
    "    \n",
    "    frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    hands_detected = hands.process(frame_rgb)\n",
    "    frame = cv.cvtColor(frame_rgb, cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    if hands_detected.multi_hand_landmarks:\n",
    "        for hand_landmarks in hands_detected.multi_hand_landmarks:\n",
    "            # Extract landmarks\n",
    "            landmark_row = []\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                landmark_row.extend([landmark.x, landmark.y, landmark.z])\n",
    "            \n",
    "            # Fill empty cells if less than 21 landmarks detected\n",
    "            while len(landmark_row) < 63:\n",
    "                landmark_row.extend([None, None, None])\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            hand_landmarks = np.array([landmark_row])\n",
    "\n",
    "\n",
    "            \n",
    "                \n",
    "                # Predict using the trained model\n",
    "            predictions = model.predict(hand_landmarks)\n",
    "            predicted_class_index = np.argmax(predictions)\n",
    "            predicted_gesture = class_names[predicted_class_index]\n",
    "                \n",
    "                # Print predictions on the screen\n",
    "                \n",
    "            \n",
    "                #frame = cv.putText(frame, predicted_gesture, org, font, fontScale, color, thickness, lineType)\n",
    "                #print(predicted_gesture)\n",
    "                \n",
    "                # Define a dictionary mapping gesture indices to actions\n",
    "                '''\n",
    "                gesture_actions = {\n",
    "                    0: lambda: ignore(),  # No action for case 0\n",
    "                    1: lambda: thumbsDown(),\n",
    "                    2: lambda: thumbsUp()  # Assuming pattern-3 corresponds to index 2\n",
    "                }\n",
    "                '''\n",
    "                \n",
    "\n",
    "            frame = cv.putText(frame, predicted_gesture, org, font, fontScale, color, thickness, lineType)\n",
    "\n",
    "            \n",
    "    \n",
    "    cv.imshow(\"Captures\", frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "cam.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34dfc0-0141-41b3-a291-3b235e2f478c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Kernel",
   "language": "python",
   "name": "ml-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
