{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aecfc27-a26f-4feb-b25a-2692fc67fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32956122-aed8-49bc-a309-1d8aea3f03b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load('E:\\Sharvil\\Code\\PBL SEM IV\\Computer Vision\\ml_model.pkl')\n",
    "class_names = ['noGesture','ThumbsDown','ThumbsUp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328f5d13-3410-4f43-8c75-2582ec10f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import win32gui\n",
    "import win32process\n",
    "import win32api\n",
    "import win32con\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "from tkinter import *\n",
    "import subprocess\n",
    "from PIL import Image,ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a013a6f8-93ad-4e6d-9ea1-60df5e009a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key pressed. Exiting...\n",
      "Inside exit_program\n"
     ]
    }
   ],
   "source": [
    "should_exit = False\n",
    "\n",
    "def exit_program():\n",
    "    global should_exit\n",
    "    start_button.config(state='normal')  # Enable the start button when exiting\n",
    "    print(\"Inside exit_program\")\n",
    "    should_exit = True\n",
    "\n",
    "thumbs_up = False\n",
    "thumbs_up_2 = False\n",
    "thumbs_up_3 = 0\n",
    "    \n",
    "thumbs_down = False\n",
    "thumbs_down_2 = False\n",
    "thumbs_down_3=0\n",
    "tic_up = 0\n",
    "tic_down = 0\n",
    "\n",
    "def gesture_recognition():\n",
    "    global should_exit\n",
    "    start_button.config(state='disabled')\n",
    "    \n",
    "    def get_active_browser_title():\n",
    "        window = win32gui.GetForegroundWindow()\n",
    "        pid = win32process.GetWindowThreadProcessId(window)[1]\n",
    "        handle = win32api.OpenProcess(win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ, False, pid)\n",
    "        exe_path = win32process.GetModuleFileNameEx(handle, 0)\n",
    "        return os.path.basename(exe_path)\n",
    "    \n",
    "    def is_doc_viewer_application(application):\n",
    "        doc_viewer_application_list = ['explorer.exe', 'vlc.exe', 'AcroRd32.exe', 'FoxitReader.exe', 'NotroPDFReader.exe', 'SumatraPDF.exe', 'PDFXEdit.exe', 'WINWORD.EXE', 'EXCEL.EXE', 'POWERPNT.EXE', 'Acrobat.exe', 'notepad.exe', 'write.exe']\n",
    "        return any(app.lower() in application.lower() for app in doc_viewer_application_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # MediaPipe initialization\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Video capture initialization\n",
    "    cam = cv.VideoCapture(0)\n",
    "    global thumbs_up, thumbs_up_2, thumbs_up_3, thumbs_down, thumbs_down_2, thumbs_down_3, tic_up, tic_down\n",
    "    \n",
    "    def thumbsUp():\n",
    "        global thumbs_up, thumbs_up_2, thumbs_up_3, tic_up\n",
    "        if thumbs_up:\n",
    "            if time.perf_counter() - tic_up > 1:\n",
    "                thumbs_up_2 = True\n",
    "                thumbs_up_3+=1\n",
    "            \n",
    "        else:\n",
    "            thumbs_up = True\n",
    "            tic_up = time.perf_counter()\n",
    "    \n",
    "        if thumbs_up_2:\n",
    "            if thumbs_up_3 == 1:\n",
    "                if active_browser_title.lower() == \"vlc.exe\":\n",
    "                    pyautogui.press(\"space\")\n",
    "    \n",
    "                else:\n",
    "                    pyautogui.press(\"right\")\n",
    "                                    \n",
    "                thumbs_up = False\n",
    "                thumbs_up_2 = False\n",
    "                thumbs_up_3 = 0\n",
    "                tic_up = 0\n",
    "            \n",
    "                        \n",
    "        # Reset thumbs-down variables when thumbs-up is detected\n",
    "        thumbs_down = False\n",
    "        thumbs_down_2 = False\n",
    "        thumbs_down_3=0\n",
    "    \n",
    "    \n",
    "    def thumbsDown():\n",
    "        global thumbs_down, thumbs_down_2, thumbs_down_3, tic_down\n",
    "        if thumbs_down:\n",
    "            if time.perf_counter() - tic_down > 1:\n",
    "                thumbs_down_2 = True\n",
    "                thumbs_down_3+=1\n",
    "            \n",
    "        else:\n",
    "            thumbs_down = True\n",
    "            tic_down = time.perf_counter()\n",
    "    \n",
    "        if thumbs_down_2:\n",
    "            if thumbs_down_3 == 1:    \n",
    "                pyautogui.press(\"left\")\n",
    "                \n",
    "                thumbs_down = False\n",
    "                thumbs_down_2 = False\n",
    "                thumbs_down_3=0\n",
    "                tic_down = 0\n",
    "                \n",
    "                        \n",
    "        # Reset thumbs-up variables when thumbs-down is detected\n",
    "        thumbs_up = False\n",
    "        thumbs_up_2 = False\n",
    "        thumbs_up_3=0\n",
    "    \n",
    "    \n",
    "    def ignore():\n",
    "        global thumbs_up, thumbs_up_2, thumbs_up_3, thumbs_down, thumbs_down_2, thumbs_down_3\n",
    "        \n",
    "        thumbs_up=False\n",
    "        thumbs_up_2 = False\n",
    "        thumbs_up_3=0 \n",
    "        thumbs_down = False\n",
    "        thumbs_down_2 = False\n",
    "        thumbs_down_3=0    \n",
    "    \n",
    "    # Main loop for capturing hand landmarks and making predictions\n",
    "    while not should_exit:            \n",
    "        success, frame = cam.read()\n",
    "        if not success:\n",
    "            print(\"No frame to show\")\n",
    "            continue\n",
    "        \n",
    "        frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        hands_detected = hands.process(frame_rgb)\n",
    "        frame = cv.cvtColor(frame_rgb, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        if hands_detected.multi_hand_landmarks:\n",
    "            for hand_landmarks in hands_detected.multi_hand_landmarks:\n",
    "                # Extract landmarks\n",
    "                landmark_row = []\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    landmark_row.extend([landmark.x, landmark.y, landmark.z])\n",
    "                \n",
    "                # Fill empty cells if less than 21 landmarks detected\n",
    "                while len(landmark_row) < 63:\n",
    "                    landmark_row.extend([None, None, None])\n",
    "                \n",
    "                # Convert to numpy array\n",
    "                hand_landmarks = np.array([landmark_row])\n",
    "    \n",
    "    \n",
    "                active_browser_title = get_active_browser_title()\n",
    "                if active_browser_title and is_doc_viewer_application(active_browser_title):\n",
    "                    \n",
    "                    # Predict using the trained model\n",
    "                    predictions = loaded_model.predict(hand_landmarks)\n",
    "                    predicted_class_index = np.argmax(predictions)\n",
    "                    predicted_gesture = class_names[predicted_class_index]\n",
    "                    \n",
    "                    # Print predictions on the screen\n",
    "                    org = (50, 50)  # Origin point for text\n",
    "                    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "                    fontScale = 1\n",
    "                    color = (255, 255, 255)  # White color\n",
    "                    thickness = 2\n",
    "                    lineType = cv.LINE_AA\n",
    "                \n",
    "                    frame = cv.putText(frame, predicted_gesture, org, font, fontScale, color, thickness, lineType)\n",
    "                    print(predicted_gesture)\n",
    "                    \n",
    "                    # Define a dictionary mapping gesture indices to actions\n",
    "                    gesture_actions = {\n",
    "                        0: lambda: ignore(),  # No action for case 0\n",
    "                        1: lambda: thumbsDown(),\n",
    "                        2: lambda: thumbsUp()  # Assuming pattern-3 corresponds to index 2\n",
    "                    }\n",
    "                    \n",
    "                    if predicted_class_index in gesture_actions:\n",
    "                        gesture_actions[predicted_class_index]()\n",
    "    \n",
    "                \n",
    "        \n",
    "        cv.imshow(\"Captures\", frame)\n",
    "        key = cv.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "            \n",
    "        elif key != 255:  # Check if any key is pressed\n",
    "            print(\"Key pressed. Exiting...\")\n",
    "            break\n",
    "        \n",
    "    \n",
    "    # Release video capture and close all windows\n",
    "    cam.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "root.title('Gesture Recognition')\n",
    "\n",
    "root.configure(borderwidth=40, relief='groove')\n",
    "    \n",
    "\n",
    "###On Screen Buttons/Frames\n",
    "def thumbs_up_description():\n",
    "    description_label.config(text=\"By showing thumbs up, user is navigated to next slide easily,\")\n",
    "\n",
    "def thumbs_down_description():\n",
    "    description_l.config(text= \"By showing thumbs down,user is navigated to previous slide easily,\")\n",
    "    \n",
    "start_button = Button(root, text='Start', padx=10, pady=10, anchor=E, command= gesture_recognition)\n",
    "start_button.grid(row=1, column=0)\n",
    "\n",
    "exit_button = Button(root, text='Exit', padx=10, pady=10, anchor=W, command=exit_program)\n",
    "exit_button.grid(row=1, column=2)\n",
    "\n",
    "#frame1 = LabelFrame(root, text='camera options', padx= 10, pady=10, labelanchor='n', command=root.quit)\n",
    "frame1 = LabelFrame(root, text='camera options', padx=10, pady=10, labelanchor='n')\n",
    "\n",
    "frame1.grid(row=2, column=1)\n",
    "\n",
    "title0 = Label(root, text='   GEST DO IT !  ', padx=20, pady=20, font=('Cooper Black', 18)).grid(row=0, column=0, columnspan=3)\n",
    "\n",
    "#images in frame\n",
    "\n",
    "frame0 = LabelFrame(root, text='gesture options', padx=10, pady=20, labelanchor='n')\n",
    "frame0.grid(row=3, column=0, columnspan=3)\n",
    "\n",
    "#tu_img = ImageTk.PhotoImage(Image.open(r'E:\\Sharvil\\Code\\PBL SEM IV\\Front-End\\up.png'))\n",
    "#add this as a parameter in tu_label ---> image = tu_img\n",
    "tu_label = Label(frame0).grid(row=0, column=0)\n",
    "# Create a button with the specified text and font, and associate the command\n",
    "thumbs_up_button = Label(frame0, text='Document:Next Slide!'+'\\n'+'PPT : Next Slide\\n VLC:Pause/Play', font=('Bookman Old Style', 12))\n",
    "thumbs_up_button.grid(row=0, column=2)\n",
    "\n",
    "description_label = Label(frame0, text=\"\", font=('Bookman Old Style', 12))\n",
    "description_label.grid(row=1 , column=2)\n",
    "\n",
    "\n",
    "#td_img = ImageTk.PhotoImage(Image.open('E:\\Sharvil\\Code\\PBL SEM IV\\Front-End\\down.jpg'))\n",
    "#add this as a parameter in td_label ---> image = td_img\n",
    "td_label = Label(frame0).grid(row=2, column=2)\n",
    " #Create a button with the specified text and font, and associate the command\n",
    "thumbs_down_button = Label(frame0, text='Document:Previous Page!'+'\\n'+'PPT : Previous Slide', font=('Bookman Old Style', 12))\n",
    "thumbs_down_button.grid(row=2, column=0)\n",
    "\n",
    "description_l = Label(frame0, text=\"\", font=('Bookman Old Style', 12))\n",
    "description_l.grid(row=3 , column=0)\n",
    "\n",
    "#filler0 = Label(root, row)\n",
    "\n",
    "#Modes for radio button/creation of radio button/storing radio input\n",
    "Modes = {\n",
    "    (\"default\",\"0\"),\n",
    "    (\"external\",\"1\"),\n",
    "}\n",
    "\n",
    "\n",
    "#Camera=StringVar()\n",
    "#Camera.set(\"0\")\n",
    "#for text, mode in Modes:\n",
    "    #Radiobutton(frame1, text=text, variable=Camera, value=mode).pack()\n",
    "\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9ed98-4855-4715-8426-882b0bdeee60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Kernel",
   "language": "python",
   "name": "ml-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
